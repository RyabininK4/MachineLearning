{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Название: Генератор базы данных Waveform (написано на C)\n",
    "Ссылка на dataset: http://archive.ics.uci.edu/ml/datasets/Waveform+Database+Generator+%28Version+1%29\n",
    "\n",
    "Имеется 3 класса волн и 21 атрибут\n",
    "Цель: научиться определять к какому из трех классов относится волна"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.plotting import scatter_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтение данных из файла"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 22)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>h1</th>\n",
       "      <th>h2</th>\n",
       "      <th>h3</th>\n",
       "      <th>h4</th>\n",
       "      <th>h5</th>\n",
       "      <th>h6</th>\n",
       "      <th>h7</th>\n",
       "      <th>h8</th>\n",
       "      <th>h9</th>\n",
       "      <th>h10</th>\n",
       "      <th>...</th>\n",
       "      <th>h13</th>\n",
       "      <th>h14</th>\n",
       "      <th>h15</th>\n",
       "      <th>h16</th>\n",
       "      <th>h17</th>\n",
       "      <th>h18</th>\n",
       "      <th>h19</th>\n",
       "      <th>h20</th>\n",
       "      <th>h21</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.23</td>\n",
       "      <td>-1.56</td>\n",
       "      <td>-1.75</td>\n",
       "      <td>-0.28</td>\n",
       "      <td>0.60</td>\n",
       "      <td>2.22</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.21</td>\n",
       "      <td>-0.20</td>\n",
       "      <td>0.89</td>\n",
       "      <td>...</td>\n",
       "      <td>2.89</td>\n",
       "      <td>7.75</td>\n",
       "      <td>4.59</td>\n",
       "      <td>3.15</td>\n",
       "      <td>5.12</td>\n",
       "      <td>3.32</td>\n",
       "      <td>1.20</td>\n",
       "      <td>0.24</td>\n",
       "      <td>-0.56</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.69</td>\n",
       "      <td>2.43</td>\n",
       "      <td>0.61</td>\n",
       "      <td>2.08</td>\n",
       "      <td>2.30</td>\n",
       "      <td>3.25</td>\n",
       "      <td>5.52</td>\n",
       "      <td>4.55</td>\n",
       "      <td>2.97</td>\n",
       "      <td>2.22</td>\n",
       "      <td>...</td>\n",
       "      <td>1.24</td>\n",
       "      <td>1.89</td>\n",
       "      <td>1.88</td>\n",
       "      <td>-1.34</td>\n",
       "      <td>0.83</td>\n",
       "      <td>1.41</td>\n",
       "      <td>1.78</td>\n",
       "      <td>0.60</td>\n",
       "      <td>2.42</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.12</td>\n",
       "      <td>-0.94</td>\n",
       "      <td>1.29</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.42</td>\n",
       "      <td>3.55</td>\n",
       "      <td>4.94</td>\n",
       "      <td>3.25</td>\n",
       "      <td>1.90</td>\n",
       "      <td>2.07</td>\n",
       "      <td>...</td>\n",
       "      <td>2.50</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1.41</td>\n",
       "      <td>2.78</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.62</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.79</td>\n",
       "      <td>-0.12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.86</td>\n",
       "      <td>0.29</td>\n",
       "      <td>2.19</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>1.13</td>\n",
       "      <td>2.51</td>\n",
       "      <td>2.37</td>\n",
       "      <td>5.45</td>\n",
       "      <td>5.45</td>\n",
       "      <td>4.84</td>\n",
       "      <td>...</td>\n",
       "      <td>2.58</td>\n",
       "      <td>1.40</td>\n",
       "      <td>1.24</td>\n",
       "      <td>1.41</td>\n",
       "      <td>1.07</td>\n",
       "      <td>-1.43</td>\n",
       "      <td>2.84</td>\n",
       "      <td>-1.18</td>\n",
       "      <td>1.12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.16</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.40</td>\n",
       "      <td>-0.59</td>\n",
       "      <td>2.66</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.69</td>\n",
       "      <td>4.06</td>\n",
       "      <td>5.34</td>\n",
       "      <td>3.53</td>\n",
       "      <td>...</td>\n",
       "      <td>4.30</td>\n",
       "      <td>1.84</td>\n",
       "      <td>1.73</td>\n",
       "      <td>0.21</td>\n",
       "      <td>-0.18</td>\n",
       "      <td>0.13</td>\n",
       "      <td>-0.21</td>\n",
       "      <td>-0.80</td>\n",
       "      <td>-0.68</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     h1    h2    h3    h4    h5    h6    h7    h8    h9   h10  ...     h13  \\\n",
       "0 -1.23 -1.56 -1.75 -0.28  0.60  2.22  0.85  0.21 -0.20  0.89  ...    2.89   \n",
       "1 -0.69  2.43  0.61  2.08  2.30  3.25  5.52  4.55  2.97  2.22  ...    1.24   \n",
       "2 -0.12 -0.94  1.29  2.59  2.42  3.55  4.94  3.25  1.90  2.07  ...    2.50   \n",
       "3  0.86  0.29  2.19 -0.02  1.13  2.51  2.37  5.45  5.45  4.84  ...    2.58   \n",
       "4  1.16  0.37  0.40 -0.59  2.66  1.00  2.69  4.06  5.34  3.53  ...    4.30   \n",
       "\n",
       "    h14   h15   h16   h17   h18   h19   h20   h21  class  \n",
       "0  7.75  4.59  3.15  5.12  3.32  1.20  0.24 -0.56      2  \n",
       "1  1.89  1.88 -1.34  0.83  1.41  1.78  0.60  2.42      1  \n",
       "2  0.12  1.41  2.78  0.64  0.62 -0.01 -0.79 -0.12      0  \n",
       "3  1.40  1.24  1.41  1.07 -1.43  2.84 -1.18  1.12      1  \n",
       "4  1.84  1.73  0.21 -0.18  0.13 -0.21 -0.80 -0.68      1  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('waveform.csv')\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>h1</th>\n",
       "      <th>h2</th>\n",
       "      <th>h3</th>\n",
       "      <th>h4</th>\n",
       "      <th>h5</th>\n",
       "      <th>h6</th>\n",
       "      <th>h7</th>\n",
       "      <th>h8</th>\n",
       "      <th>h9</th>\n",
       "      <th>h10</th>\n",
       "      <th>...</th>\n",
       "      <th>h13</th>\n",
       "      <th>h14</th>\n",
       "      <th>h15</th>\n",
       "      <th>h16</th>\n",
       "      <th>h17</th>\n",
       "      <th>h18</th>\n",
       "      <th>h19</th>\n",
       "      <th>h20</th>\n",
       "      <th>h21</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.005144</td>\n",
       "      <td>0.338746</td>\n",
       "      <td>0.672438</td>\n",
       "      <td>0.991610</td>\n",
       "      <td>1.310888</td>\n",
       "      <td>1.997306</td>\n",
       "      <td>2.661806</td>\n",
       "      <td>2.659228</td>\n",
       "      <td>2.672086</td>\n",
       "      <td>2.988668</td>\n",
       "      <td>...</td>\n",
       "      <td>2.678908</td>\n",
       "      <td>2.648632</td>\n",
       "      <td>2.647668</td>\n",
       "      <td>2.000504</td>\n",
       "      <td>1.335032</td>\n",
       "      <td>1.000622</td>\n",
       "      <td>0.661482</td>\n",
       "      <td>0.357300</td>\n",
       "      <td>-0.021378</td>\n",
       "      <td>1.007800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.010130</td>\n",
       "      <td>1.053657</td>\n",
       "      <td>1.187970</td>\n",
       "      <td>1.415239</td>\n",
       "      <td>1.678291</td>\n",
       "      <td>1.814187</td>\n",
       "      <td>2.015774</td>\n",
       "      <td>1.746067</td>\n",
       "      <td>1.663277</td>\n",
       "      <td>1.531506</td>\n",
       "      <td>...</td>\n",
       "      <td>1.651588</td>\n",
       "      <td>1.760113</td>\n",
       "      <td>2.018768</td>\n",
       "      <td>1.810684</td>\n",
       "      <td>1.669949</td>\n",
       "      <td>1.412815</td>\n",
       "      <td>1.197326</td>\n",
       "      <td>1.081337</td>\n",
       "      <td>0.997064</td>\n",
       "      <td>0.818946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-3.340000</td>\n",
       "      <td>-3.250000</td>\n",
       "      <td>-4.200000</td>\n",
       "      <td>-3.840000</td>\n",
       "      <td>-3.480000</td>\n",
       "      <td>-2.760000</td>\n",
       "      <td>-3.320000</td>\n",
       "      <td>-3.520000</td>\n",
       "      <td>-3.380000</td>\n",
       "      <td>-1.790000</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.610000</td>\n",
       "      <td>-2.820000</td>\n",
       "      <td>-2.560000</td>\n",
       "      <td>-2.990000</td>\n",
       "      <td>-3.560000</td>\n",
       "      <td>-4.080000</td>\n",
       "      <td>-3.500000</td>\n",
       "      <td>-3.570000</td>\n",
       "      <td>-3.880000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.680000</td>\n",
       "      <td>-0.372500</td>\n",
       "      <td>-0.150000</td>\n",
       "      <td>-0.020000</td>\n",
       "      <td>0.037500</td>\n",
       "      <td>0.590000</td>\n",
       "      <td>1.110000</td>\n",
       "      <td>1.390000</td>\n",
       "      <td>1.470000</td>\n",
       "      <td>1.880000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.480000</td>\n",
       "      <td>1.360000</td>\n",
       "      <td>1.120000</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>-0.010000</td>\n",
       "      <td>-0.180000</td>\n",
       "      <td>-0.350000</td>\n",
       "      <td>-0.690000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.340000</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>0.940000</td>\n",
       "      <td>1.120000</td>\n",
       "      <td>1.860000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>2.720000</td>\n",
       "      <td>2.810000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.830000</td>\n",
       "      <td>2.700000</td>\n",
       "      <td>2.490000</td>\n",
       "      <td>1.820000</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>0.940000</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>-0.030000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.690000</td>\n",
       "      <td>1.050000</td>\n",
       "      <td>1.460000</td>\n",
       "      <td>1.970000</td>\n",
       "      <td>2.540000</td>\n",
       "      <td>3.340000</td>\n",
       "      <td>4.210000</td>\n",
       "      <td>3.940000</td>\n",
       "      <td>3.940000</td>\n",
       "      <td>4.080000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.932500</td>\n",
       "      <td>3.980000</td>\n",
       "      <td>4.182500</td>\n",
       "      <td>3.330000</td>\n",
       "      <td>2.532500</td>\n",
       "      <td>1.960000</td>\n",
       "      <td>1.470000</td>\n",
       "      <td>1.072500</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.940000</td>\n",
       "      <td>3.880000</td>\n",
       "      <td>4.720000</td>\n",
       "      <td>5.750000</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>7.620000</td>\n",
       "      <td>8.760000</td>\n",
       "      <td>7.840000</td>\n",
       "      <td>7.900000</td>\n",
       "      <td>7.630000</td>\n",
       "      <td>...</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>7.750000</td>\n",
       "      <td>8.720000</td>\n",
       "      <td>7.860000</td>\n",
       "      <td>6.740000</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>5.280000</td>\n",
       "      <td>4.650000</td>\n",
       "      <td>4.010000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                h1           h2           h3           h4           h5  \\\n",
       "count  5000.000000  5000.000000  5000.000000  5000.000000  5000.000000   \n",
       "mean      0.005144     0.338746     0.672438     0.991610     1.310888   \n",
       "std       1.010130     1.053657     1.187970     1.415239     1.678291   \n",
       "min      -3.340000    -3.250000    -4.200000    -3.840000    -3.480000   \n",
       "25%      -0.680000    -0.372500    -0.150000    -0.020000     0.037500   \n",
       "50%       0.010000     0.340000     0.660000     0.940000     1.120000   \n",
       "75%       0.690000     1.050000     1.460000     1.970000     2.540000   \n",
       "max       3.940000     3.880000     4.720000     5.750000     6.500000   \n",
       "\n",
       "                h6           h7           h8           h9          h10  \\\n",
       "count  5000.000000  5000.000000  5000.000000  5000.000000  5000.000000   \n",
       "mean      1.997306     2.661806     2.659228     2.672086     2.988668   \n",
       "std       1.814187     2.015774     1.746067     1.663277     1.531506   \n",
       "min      -2.760000    -3.320000    -3.520000    -3.380000    -1.790000   \n",
       "25%       0.590000     1.110000     1.390000     1.470000     1.880000   \n",
       "50%       1.860000     2.500000     2.720000     2.810000     3.000000   \n",
       "75%       3.340000     4.210000     3.940000     3.940000     4.080000   \n",
       "max       7.620000     8.760000     7.840000     7.900000     7.630000   \n",
       "\n",
       "          ...               h13          h14          h15          h16  \\\n",
       "count     ...       5000.000000  5000.000000  5000.000000  5000.000000   \n",
       "mean      ...          2.678908     2.648632     2.647668     2.000504   \n",
       "std       ...          1.651588     1.760113     2.018768     1.810684   \n",
       "min       ...         -2.610000    -2.820000    -2.560000    -2.990000   \n",
       "25%       ...          1.480000     1.360000     1.120000     0.640000   \n",
       "50%       ...          2.830000     2.700000     2.490000     1.820000   \n",
       "75%       ...          3.932500     3.980000     4.182500     3.330000   \n",
       "max       ...          7.500000     7.750000     8.720000     7.860000   \n",
       "\n",
       "               h17          h18          h19          h20          h21  \\\n",
       "count  5000.000000  5000.000000  5000.000000  5000.000000  5000.000000   \n",
       "mean      1.335032     1.000622     0.661482     0.357300    -0.021378   \n",
       "std       1.669949     1.412815     1.197326     1.081337     0.997064   \n",
       "min      -3.560000    -4.080000    -3.500000    -3.570000    -3.880000   \n",
       "25%       0.070000    -0.010000    -0.180000    -0.350000    -0.690000   \n",
       "50%       1.200000     0.940000     0.620000     0.350000    -0.030000   \n",
       "75%       2.532500     1.960000     1.470000     1.072500     0.660000   \n",
       "max       6.740000     6.200000     5.280000     4.650000     4.010000   \n",
       "\n",
       "             class  \n",
       "count  5000.000000  \n",
       "mean      1.007800  \n",
       "std       0.818946  \n",
       "min       0.000000  \n",
       "25%       0.000000  \n",
       "50%       1.000000  \n",
       "75%       2.000000  \n",
       "max       2.000000  \n",
       "\n",
       "[8 rows x 22 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На таблице отобразим распределение данных по классам, получили примерное разделение по 33% на каждый класс."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data['class'].value_counts().plot.barh()\n",
    "plt.xlabel('count')\n",
    "plt.ylabel('class')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подготавливаем данные для обучения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 21) (5000,)\n"
     ]
    }
   ],
   "source": [
    "X = data.drop(['class'], axis=1)\n",
    "y = data['class']\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "['h1', 'h2', 'h3', 'h4', 'h5', 'h6', 'h7', 'h8', 'h9', 'h10', 'h11', 'h12', 'h13', 'h14', 'h15', 'h16', 'h17', 'h18', 'h19', 'h20', 'h21']\n"
     ]
    }
   ],
   "source": [
    "categorical_columns = [c for c in X.columns if X[c].dtype.name == 'object']\n",
    "numerical_columns = [c for c in X.columns if X[c].dtype.name != 'object']\n",
    "print(categorical_columns)\n",
    "print(numerical_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Числовые данные нормализуем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_numerical = X[numerical_columns]\n",
    "data_numerical = (data_numerical - data_numerical.mean(axis=0)) / data_numerical.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>h1</th>\n",
       "      <th>h2</th>\n",
       "      <th>h3</th>\n",
       "      <th>h4</th>\n",
       "      <th>h5</th>\n",
       "      <th>h6</th>\n",
       "      <th>h7</th>\n",
       "      <th>h8</th>\n",
       "      <th>h9</th>\n",
       "      <th>h10</th>\n",
       "      <th>...</th>\n",
       "      <th>h12</th>\n",
       "      <th>h13</th>\n",
       "      <th>h14</th>\n",
       "      <th>h15</th>\n",
       "      <th>h16</th>\n",
       "      <th>h17</th>\n",
       "      <th>h18</th>\n",
       "      <th>h19</th>\n",
       "      <th>h20</th>\n",
       "      <th>h21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.005144</td>\n",
       "      <td>0.338746</td>\n",
       "      <td>0.672438</td>\n",
       "      <td>0.991610</td>\n",
       "      <td>1.310888</td>\n",
       "      <td>1.997306</td>\n",
       "      <td>2.661806</td>\n",
       "      <td>2.659228</td>\n",
       "      <td>2.672086</td>\n",
       "      <td>2.988668</td>\n",
       "      <td>...</td>\n",
       "      <td>3.013614</td>\n",
       "      <td>2.678908</td>\n",
       "      <td>2.648632</td>\n",
       "      <td>2.647668</td>\n",
       "      <td>2.000504</td>\n",
       "      <td>1.335032</td>\n",
       "      <td>1.000622</td>\n",
       "      <td>0.661482</td>\n",
       "      <td>0.357300</td>\n",
       "      <td>-0.021378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.010130</td>\n",
       "      <td>1.053657</td>\n",
       "      <td>1.187970</td>\n",
       "      <td>1.415239</td>\n",
       "      <td>1.678291</td>\n",
       "      <td>1.814187</td>\n",
       "      <td>2.015774</td>\n",
       "      <td>1.746067</td>\n",
       "      <td>1.663277</td>\n",
       "      <td>1.531506</td>\n",
       "      <td>...</td>\n",
       "      <td>1.512448</td>\n",
       "      <td>1.651588</td>\n",
       "      <td>1.760113</td>\n",
       "      <td>2.018768</td>\n",
       "      <td>1.810684</td>\n",
       "      <td>1.669949</td>\n",
       "      <td>1.412815</td>\n",
       "      <td>1.197326</td>\n",
       "      <td>1.081337</td>\n",
       "      <td>0.997064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-3.340000</td>\n",
       "      <td>-3.250000</td>\n",
       "      <td>-4.200000</td>\n",
       "      <td>-3.840000</td>\n",
       "      <td>-3.480000</td>\n",
       "      <td>-2.760000</td>\n",
       "      <td>-3.320000</td>\n",
       "      <td>-3.520000</td>\n",
       "      <td>-3.380000</td>\n",
       "      <td>-1.790000</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.690000</td>\n",
       "      <td>-2.610000</td>\n",
       "      <td>-2.820000</td>\n",
       "      <td>-2.560000</td>\n",
       "      <td>-2.990000</td>\n",
       "      <td>-3.560000</td>\n",
       "      <td>-4.080000</td>\n",
       "      <td>-3.500000</td>\n",
       "      <td>-3.570000</td>\n",
       "      <td>-3.880000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.680000</td>\n",
       "      <td>-0.372500</td>\n",
       "      <td>-0.150000</td>\n",
       "      <td>-0.020000</td>\n",
       "      <td>0.037500</td>\n",
       "      <td>0.590000</td>\n",
       "      <td>1.110000</td>\n",
       "      <td>1.390000</td>\n",
       "      <td>1.470000</td>\n",
       "      <td>1.880000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.920000</td>\n",
       "      <td>1.480000</td>\n",
       "      <td>1.360000</td>\n",
       "      <td>1.120000</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>-0.010000</td>\n",
       "      <td>-0.180000</td>\n",
       "      <td>-0.350000</td>\n",
       "      <td>-0.690000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.340000</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>0.940000</td>\n",
       "      <td>1.120000</td>\n",
       "      <td>1.860000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>2.720000</td>\n",
       "      <td>2.810000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.830000</td>\n",
       "      <td>2.700000</td>\n",
       "      <td>2.490000</td>\n",
       "      <td>1.820000</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>0.940000</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>-0.030000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.690000</td>\n",
       "      <td>1.050000</td>\n",
       "      <td>1.460000</td>\n",
       "      <td>1.970000</td>\n",
       "      <td>2.540000</td>\n",
       "      <td>3.340000</td>\n",
       "      <td>4.210000</td>\n",
       "      <td>3.940000</td>\n",
       "      <td>3.940000</td>\n",
       "      <td>4.080000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.082500</td>\n",
       "      <td>3.932500</td>\n",
       "      <td>3.980000</td>\n",
       "      <td>4.182500</td>\n",
       "      <td>3.330000</td>\n",
       "      <td>2.532500</td>\n",
       "      <td>1.960000</td>\n",
       "      <td>1.470000</td>\n",
       "      <td>1.072500</td>\n",
       "      <td>0.660000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.940000</td>\n",
       "      <td>3.880000</td>\n",
       "      <td>4.720000</td>\n",
       "      <td>5.750000</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>7.620000</td>\n",
       "      <td>8.760000</td>\n",
       "      <td>7.840000</td>\n",
       "      <td>7.900000</td>\n",
       "      <td>7.630000</td>\n",
       "      <td>...</td>\n",
       "      <td>7.400000</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>7.750000</td>\n",
       "      <td>8.720000</td>\n",
       "      <td>7.860000</td>\n",
       "      <td>6.740000</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>5.280000</td>\n",
       "      <td>4.650000</td>\n",
       "      <td>4.010000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                h1           h2           h3           h4           h5  \\\n",
       "count  5000.000000  5000.000000  5000.000000  5000.000000  5000.000000   \n",
       "mean      0.005144     0.338746     0.672438     0.991610     1.310888   \n",
       "std       1.010130     1.053657     1.187970     1.415239     1.678291   \n",
       "min      -3.340000    -3.250000    -4.200000    -3.840000    -3.480000   \n",
       "25%      -0.680000    -0.372500    -0.150000    -0.020000     0.037500   \n",
       "50%       0.010000     0.340000     0.660000     0.940000     1.120000   \n",
       "75%       0.690000     1.050000     1.460000     1.970000     2.540000   \n",
       "max       3.940000     3.880000     4.720000     5.750000     6.500000   \n",
       "\n",
       "                h6           h7           h8           h9          h10  \\\n",
       "count  5000.000000  5000.000000  5000.000000  5000.000000  5000.000000   \n",
       "mean      1.997306     2.661806     2.659228     2.672086     2.988668   \n",
       "std       1.814187     2.015774     1.746067     1.663277     1.531506   \n",
       "min      -2.760000    -3.320000    -3.520000    -3.380000    -1.790000   \n",
       "25%       0.590000     1.110000     1.390000     1.470000     1.880000   \n",
       "50%       1.860000     2.500000     2.720000     2.810000     3.000000   \n",
       "75%       3.340000     4.210000     3.940000     3.940000     4.080000   \n",
       "max       7.620000     8.760000     7.840000     7.900000     7.630000   \n",
       "\n",
       "          ...               h12          h13          h14          h15  \\\n",
       "count     ...       5000.000000  5000.000000  5000.000000  5000.000000   \n",
       "mean      ...          3.013614     2.678908     2.648632     2.647668   \n",
       "std       ...          1.512448     1.651588     1.760113     2.018768   \n",
       "min       ...         -1.690000    -2.610000    -2.820000    -2.560000   \n",
       "25%       ...          1.920000     1.480000     1.360000     1.120000   \n",
       "50%       ...          3.000000     2.830000     2.700000     2.490000   \n",
       "75%       ...          4.082500     3.932500     3.980000     4.182500   \n",
       "max       ...          7.400000     7.500000     7.750000     8.720000   \n",
       "\n",
       "               h16          h17          h18          h19          h20  \\\n",
       "count  5000.000000  5000.000000  5000.000000  5000.000000  5000.000000   \n",
       "mean      2.000504     1.335032     1.000622     0.661482     0.357300   \n",
       "std       1.810684     1.669949     1.412815     1.197326     1.081337   \n",
       "min      -2.990000    -3.560000    -4.080000    -3.500000    -3.570000   \n",
       "25%       0.640000     0.070000    -0.010000    -0.180000    -0.350000   \n",
       "50%       1.820000     1.200000     0.940000     0.620000     0.350000   \n",
       "75%       3.330000     2.532500     1.960000     1.470000     1.072500   \n",
       "max       7.860000     6.740000     6.200000     5.280000     4.650000   \n",
       "\n",
       "               h21  \n",
       "count  5000.000000  \n",
       "mean     -0.021378  \n",
       "std       0.997064  \n",
       "min      -3.880000  \n",
       "25%      -0.690000  \n",
       "50%      -0.030000  \n",
       "75%       0.660000  \n",
       "max       4.010000  \n",
       "\n",
       "[8 rows x 21 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 21) Index(['h1', 'h2', 'h3', 'h4', 'h5', 'h6', 'h7', 'h8', 'h9', 'h10', 'h11',\n",
      "       'h12', 'h13', 'h14', 'h15', 'h16', 'h17', 'h18', 'h19', 'h20', 'h21'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "X = pd.DataFrame(data_numerical, dtype = int)\n",
    "print(X.shape, X.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделяем данные на два типа: 1 - тренировочные, 2 - тестовые"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000, 21)\n",
      "(1000, 21)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Классификатор k-ближайших соседей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подсчет и вывод ошибки на тренировочных и тестовых данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ошибка на тренировочных:  0.168\n",
      "Ошибка на тестовых:  0.253\n"
     ]
    }
   ],
   "source": [
    "y_train_predict = knn.predict(X_train)\n",
    "y_test_predict = knn.predict(X_test)\n",
    "\n",
    "err_train = np.mean(y_train != y_train_predict)\n",
    "err_test = np.mean(y_test != y_test_predict)\n",
    "\n",
    "print(\"Ошибка на тренировочных: \", err_train)\n",
    "print(\"Ошибка на тестовых: \", err_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Применим метод кросс-валидации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21299999999999997 55\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "nnb = [50, 55, 60, 65, 70, 75]\n",
    "knn = KNeighborsClassifier()\n",
    "grid = GridSearchCV(knn, param_grid={'n_neighbors': nnb}, cv=5)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "best_cv_err = 1 - grid.best_score_\n",
    "best_n_neighbors = grid.best_estimator_.n_neighbors\n",
    "print(best_cv_err, best_n_neighbors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В результате получили, что оптимальное количество соседей = 55"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим какие результаты выдаст классификатор k-ближайших соседей с заданным (оптимальным) количеством соседей:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ошибка на тренировочных:  0.2015\n",
      "Ошибка на тестовых:  0.203\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=best_n_neighbors)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "err_train = np.mean(y_train != knn.predict(X_train))\n",
    "err_test  = np.mean(y_test  != knn.predict(X_test))\n",
    "\n",
    "print(\"Ошибка на тренировочных: \", err_train)\n",
    "print(\"Ошибка на тестовых: \", err_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В результте получили, что ошибка на тренировочных и тестовых данных будет примерно 20%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Классификатор Нейронная сеть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(200,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=300, momentum=0.9,\n",
       "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=42, shuffle=True, solver='adam', tol=0.0001,\n",
       "       validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp_model = MLPClassifier(hidden_layer_sizes=(200,), solver='adam', activation='relu', random_state=42, max_iter=300)\n",
    "mlp_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подсчет и вывод ошибки на тренировочных и тестовых данных. Результат: переобучение."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ошибка на тренировочных:  0.01425\n",
      "Ошибка на тестовых:  0.225\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = mlp_model.predict(X_train)\n",
    "y_test_pred = mlp_model.predict(X_test)\n",
    "\n",
    "err_train = np.mean(y_train != y_train_pred)\n",
    "err_test = np.mean(y_test != y_test_pred)\n",
    "\n",
    "print(\"Ошибка на тренировочных: \", err_train)\n",
    "print(\"Ошибка на тестовых: \", err_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проведем эксперементы с разными видами решателями (solvers), функциями активации (activations) и размерами слоя (layer_sizes). Определим оптимальные параметры."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['sgd', 'identity', 2, 0.18525, 0.171]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "solvers = ['lbfgs', 'sgd', 'adam']\n",
    "activations = ['identity', 'logistic', 'tanh', 'relu']\n",
    "layer_sizes = [1, 2, 5, 10, 20, 50, 100, 200]\n",
    "\n",
    "min_test_error = 1\n",
    "results = []\n",
    "\n",
    "for solver in solvers:\n",
    "    for act in activations:\n",
    "        for size in layer_sizes:\n",
    "            if solver is 'adam':\n",
    "                mlp_model = MLPClassifier(hidden_layer_sizes=(size,), solver=solver, activation=act, random_state=42, max_iter=300)\n",
    "            else:\n",
    "                mlp_model = MLPClassifier(hidden_layer_sizes=(size,), solver=solver, activation=act, random_state=42)\n",
    "            mlp_model.fit(X_train, y_train)\n",
    "            y_train_pred = mlp_model.predict(X_train)\n",
    "            y_test_pred = mlp_model.predict(X_test)\n",
    "            \n",
    "            train_error = np.mean(y_train != y_train_pred)\n",
    "            test_error = np.mean(y_test != y_test_pred)\n",
    "            if test_error < min_test_error:\n",
    "                min_test_error = test_error\n",
    "                results.clear()\n",
    "                results.append([solver, act, size, train_error, test_error])\n",
    "\n",
    "print(results)            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Будем использовать полученные оптимальные значения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:230: RuntimeWarning: overflow encountered in double_scalars\n",
      "  loss += (0.5 * self.alpha) * values / n_samples\n",
      "/anaconda3/lib/python3.7/site-packages/numpy/core/_methods.py:28: RuntimeWarning: invalid value encountered in reduce\n",
      "  return umr_maximum(a, axis, None, out, keepdims, initial)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_base.py:91: RuntimeWarning: overflow encountered in subtract\n",
      "  tmp = X - X.max(axis=1)[:, np.newaxis]\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_base.py:91: RuntimeWarning: invalid value encountered in subtract\n",
      "  tmp = X - X.max(axis=1)[:, np.newaxis]\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/numpy/core/_methods.py:28: RuntimeWarning: invalid value encountered in reduce\n",
      "  return umr_maximum(a, axis, None, out, keepdims, initial)\n",
      "/anaconda3/lib/python3.7/site-packages/numpy/core/_methods.py:28: RuntimeWarning: invalid value encountered in reduce\n",
      "  return umr_maximum(a, axis, None, out, keepdims, initial)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:230: RuntimeWarning: overflow encountered in double_scalars\n",
      "  loss += (0.5 * self.alpha) * values / n_samples\n",
      "/anaconda3/lib/python3.7/site-packages/numpy/core/_methods.py:28: RuntimeWarning: invalid value encountered in reduce\n",
      "  return umr_maximum(a, axis, None, out, keepdims, initial)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_base.py:91: RuntimeWarning: invalid value encountered in subtract\n",
      "  tmp = X - X.max(axis=1)[:, np.newaxis]\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/numpy/core/_methods.py:28: RuntimeWarning: invalid value encountered in reduce\n",
      "  return umr_maximum(a, axis, None, out, keepdims, initial)\n",
      "/anaconda3/lib/python3.7/site-packages/numpy/core/_methods.py:28: RuntimeWarning: invalid value encountered in reduce\n",
      "  return umr_maximum(a, axis, None, out, keepdims, initial)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:230: RuntimeWarning: overflow encountered in double_scalars\n",
      "  loss += (0.5 * self.alpha) * values / n_samples\n",
      "/anaconda3/lib/python3.7/site-packages/numpy/core/_methods.py:28: RuntimeWarning: invalid value encountered in reduce\n",
      "  return umr_maximum(a, axis, None, out, keepdims, initial)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_base.py:91: RuntimeWarning: invalid value encountered in subtract\n",
      "  tmp = X - X.max(axis=1)[:, np.newaxis]\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/numpy/core/_methods.py:28: RuntimeWarning: invalid value encountered in reduce\n",
      "  return umr_maximum(a, axis, None, out, keepdims, initial)\n",
      "/anaconda3/lib/python3.7/site-packages/numpy/core/_methods.py:28: RuntimeWarning: invalid value encountered in reduce\n",
      "  return umr_maximum(a, axis, None, out, keepdims, initial)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:230: RuntimeWarning: overflow encountered in double_scalars\n",
      "  loss += (0.5 * self.alpha) * values / n_samples\n",
      "/anaconda3/lib/python3.7/site-packages/numpy/core/_methods.py:28: RuntimeWarning: invalid value encountered in reduce\n",
      "  return umr_maximum(a, axis, None, out, keepdims, initial)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/numpy/core/_methods.py:28: RuntimeWarning: invalid value encountered in reduce\n",
      "  return umr_maximum(a, axis, None, out, keepdims, initial)\n",
      "/anaconda3/lib/python3.7/site-packages/numpy/core/_methods.py:28: RuntimeWarning: invalid value encountered in reduce\n",
      "  return umr_maximum(a, axis, None, out, keepdims, initial)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:230: RuntimeWarning: overflow encountered in double_scalars\n",
      "  loss += (0.5 * self.alpha) * values / n_samples\n",
      "/anaconda3/lib/python3.7/site-packages/numpy/core/_methods.py:28: RuntimeWarning: invalid value encountered in reduce\n",
      "  return umr_maximum(a, axis, None, out, keepdims, initial)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/numpy/core/_methods.py:28: RuntimeWarning: invalid value encountered in reduce\n",
      "  return umr_maximum(a, axis, None, out, keepdims, initial)\n",
      "/anaconda3/lib/python3.7/site-packages/numpy/core/_methods.py:28: RuntimeWarning: invalid value encountered in reduce\n",
      "  return umr_maximum(a, axis, None, out, keepdims, initial)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:230: RuntimeWarning: overflow encountered in double_scalars\n",
      "  loss += (0.5 * self.alpha) * values / n_samples\n",
      "/anaconda3/lib/python3.7/site-packages/numpy/core/_methods.py:28: RuntimeWarning: invalid value encountered in reduce\n",
      "  return umr_maximum(a, axis, None, out, keepdims, initial)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_base.py:91: RuntimeWarning: overflow encountered in subtract\n",
      "  tmp = X - X.max(axis=1)[:, np.newaxis]\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_base.py:91: RuntimeWarning: invalid value encountered in subtract\n",
      "  tmp = X - X.max(axis=1)[:, np.newaxis]\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/numpy/core/_methods.py:28: RuntimeWarning: invalid value encountered in reduce\n",
      "  return umr_maximum(a, axis, None, out, keepdims, initial)\n",
      "/anaconda3/lib/python3.7/site-packages/numpy/core/_methods.py:28: RuntimeWarning: invalid value encountered in reduce\n",
      "  return umr_maximum(a, axis, None, out, keepdims, initial)\n"
     ]
    }
   ],
   "source": [
    "alpha_arr = np.logspace(-5, 10, 21)\n",
    "test_err = []\n",
    "train_err = []\n",
    "for alpha in alpha_arr:\n",
    "    mlp_model = MLPClassifier(alpha=alpha, hidden_layer_sizes=(2,), solver='sgd', \n",
    "                              activation='identity', random_state=42)\n",
    "    mlp_model.fit(X_train, y_train)\n",
    "\n",
    "    y_train_pred = mlp_model.predict(X_train)\n",
    "    y_test_pred = mlp_model.predict(X_test)\n",
    "    train_err.append(np.mean(y_train != y_train_pred))\n",
    "    test_err.append(np.mean(y_test != y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим график зависимости от alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.semilogx(alpha_arr, train_err, 'b-o', label='train')\n",
    "plt.semilogx(alpha_arr, test_err, 'r-o', label='test')\n",
    "plt.xlabel('alpha')\n",
    "plt.ylabel('error')\n",
    "plt.legend()\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Найдем оптимальные значения alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.00000000e-05 5.62341325e-05 3.16227766e-04 1.77827941e-03\n",
      " 1.00000000e-02 5.62341325e-02 3.16227766e-01 1.77827941e+00]\n"
     ]
    }
   ],
   "source": [
    "alpha_opt = alpha_arr[test_err == np.min(test_err)]\n",
    "print(alpha_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-396a6ae52fd3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0my_test_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmlp_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0merr_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mrf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0merr_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mrf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'rf' is not defined"
     ]
    }
   ],
   "source": [
    "mlp_model = MLPClassifier(alpha=alpha_opt[0], hidden_layer_sizes=(2,), solver='sgd', \n",
    "                              activation='identity', random_state=42)\n",
    "mlp_model.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = mlp_model.predict(X_train)\n",
    "y_test_pred = mlp_model.predict(X_test)\n",
    "\n",
    "err_train = np.mean(y_train != rf.predict(X_train))\n",
    "err_test = np.mean(y_test != rf.predict(X_test))\n",
    "\n",
    "print(\"Ошибка на тренировочных: \", err_train)\n",
    "print(\"Ошибка на тестовых: \", err_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Классификатор Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ошибка на тренировочных:  0.014\n",
      "Ошибка на тестовых:  0.231\n"
     ]
    }
   ],
   "source": [
    "from sklearn import ensemble\n",
    "rf = ensemble.RandomForestClassifier(n_estimators=10)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "err_train = np.mean(y_train != rf.predict(X_train))\n",
    "err_test  = np.mean(y_test  != rf.predict(X_test))\n",
    "\n",
    "print(\"Ошибка на тренировочных: \", err_train)\n",
    "print(\"Ошибка на тестовых: \", err_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/MachineLearning/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/anaconda3/envs/MachineLearning/lib/python3.7/site-packages/sklearn/ensemble/forest.py:463: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/anaconda3/envs/MachineLearning/lib/python3.7/site-packages/sklearn/ensemble/forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/anaconda3/envs/MachineLearning/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/anaconda3/envs/MachineLearning/lib/python3.7/site-packages/sklearn/ensemble/forest.py:463: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/anaconda3/envs/MachineLearning/lib/python3.7/site-packages/sklearn/ensemble/forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/anaconda3/envs/MachineLearning/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/anaconda3/envs/MachineLearning/lib/python3.7/site-packages/sklearn/ensemble/forest.py:463: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/anaconda3/envs/MachineLearning/lib/python3.7/site-packages/sklearn/ensemble/forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/anaconda3/envs/MachineLearning/lib/python3.7/site-packages/sklearn/ensemble/forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/anaconda3/envs/MachineLearning/lib/python3.7/site-packages/sklearn/ensemble/forest.py:463: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "/anaconda3/envs/MachineLearning/lib/python3.7/site-packages/sklearn/ensemble/forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "trees_arr = np.arange(1, 100, 5)\n",
    "test_err = []\n",
    "train_err = []\n",
    "oob_err = []\n",
    "\n",
    "for tree in trees_arr:\n",
    "    rf = ensemble.RandomForestClassifier(n_estimators=tree, oob_score=True)\n",
    "    rf.fit(X_train, y_train)\n",
    "    y_train_pred = rf.predict(X_train)\n",
    "    y_test_pred = rf.predict(X_test)\n",
    "    train_err.append(np.mean(y_train != y_train_pred))\n",
    "    test_err.append(np.mean(y_test != y_test_pred))\n",
    "    oob_err.append(1 - rf.oob_score_)\n",
    "    \n",
    "plt.plot(trees_arr, train_err, 'b-o', label='train')\n",
    "plt.plot(trees_arr, test_err, 'r-o', label='test')\n",
    "plt.plot(trees_arr, oob_err, 'g-o', label='test')\n",
    "plt.xlabel('trees')\n",
    "plt.ylabel('error')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В результате работы классифакатора получили переобучение."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Классификатор Extra Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ensemble' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-96ed13829579>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0moob_err\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtree\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrees_arr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mert\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensemble\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExtraTreesClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moob_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbootstrap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mert\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mtrain_err\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mert\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ensemble' is not defined"
     ]
    }
   ],
   "source": [
    "trees_arr = np.arange(1, 15, 1)\n",
    "test_err = []\n",
    "train_err = []\n",
    "oob_err = []\n",
    "for tree in trees_arr:\n",
    "    ert = ensemble.ExtraTreesClassifier(n_estimators=tree, oob_score=True, bootstrap=True)\n",
    "    ert.fit(X_train, y_train)\n",
    "    train_err.append(np.mean(y_train != ert.predict(X_train)))\n",
    "    test_err.append(np.mean(y_test != ert.predict(X_test)))\n",
    "    oob_err.append(1 - ert.oob_score_)\n",
    "\n",
    "plt.plot(trees_arr, train_err, 'b-o', label='train')\n",
    "plt.plot(trees_arr, test_err, 'r-o', label='test')\n",
    "plt.plot(trees_arr, oob_err, 'g-o', label='oob')\n",
    "plt.xlabel('Count of tree')\n",
    "plt.ylabel('Error')\n",
    "plt.legend()\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В результате работы классифакатора получили переобучение."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trees_arr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-5704176a4d52>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrees_opt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrees_arr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_err\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_err\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrees_opt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'trees_arr' is not defined"
     ]
    }
   ],
   "source": [
    "trees_opt = trees_arr[test_err == np.min(test_err)]\n",
    "print(trees_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
